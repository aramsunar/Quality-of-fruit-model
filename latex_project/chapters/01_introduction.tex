\chapter{INTRODUCTION}

The fruit quality assessment acted as the chosen scenario for the completion of this mini-project. Assessment of fruit quality remains a challenge in industries like agricultural supply chains, where classification has to happen at a fast pace with accurate results. Traditional methods of inspection work in small-scale operations but have difficulty scaling up efficiently to industrial applications. Visual assessment by human inspectors introduces variability and inconsistency, particularly when distinguishing between subtle gradations of quality. This labour intensive nature of manual sorting creates bottlenecks that may compromise both throughput and economic viability, especially in cases where time is of the essence.

Convolutional neural networks (CNNs) have emerged as a promising solution to automate fruit quality assessment through image based classification. CNNs learn hierarchical feature representations directly from pixel data, potentially capturing patterns that correlate with quality indicators such as colour, surface texture and visible features.

The task itself appears relatively simple: given labelled images categorised into discrete quality classes (Good, Mild, Rotten), a CNN should learn to distinguish among them. But this is where this project attempts to look beyond the simple objective and attempt to answer several implementation questions that arose throughout the year during classes, that remain unresolved. To what extent does colour information contribute to classification accuracy, and might grayscale representations suffice? How do different preprocessing strategies, such as data augmentation or variations in input resolution, affect model generalisation? These questions motivated our experimental design, where we systematically evaluate multiple training scenarios to understand which factors most influence performance. This is the best example of applying what has been studied as a theoretical discussion, to reflect on the practical application thereof.

Our approach involves constructing CNN architectures that process images of fruit and output quality predictions, evaluated using standard metrics such as accuracy, precision, recall, F1-score and area under the ROC curve (AUC). We implement a series of controlled experimental scenarios: baseline models with standard colour images, grayscale conversions to isolate colour dependency, augmented datasets to test robustness and multiple input. Each scenario provides insight into how specific design choices shape model behaviour, potentially revealing whether certain preprocessing steps offer marginal gains or whether simpler configurations prove sufficient for this classification task.

While the original project specification focused solely on classifying the quality of the fruit, we expanded the scope to incorporate fruit type identification as a concurrent task, thereby transforming the problem into a multi-task learning framework. This extension was motivated by two intersecting considerations.

First, the single-task formulation presented a relatively straightforward classification problem with only three output classes, offering limited opportunity to explore more interesting architectural patterns and training dynamics that exists in deep learning. By introducing an additional classification objective, identifying which specific fruit type appears in each image, we create a richer experimental context that demands more complex feature learning and allows us to investigate how shared representations can serve multiple predictive goals simultaneously.

Second, this multi-task extension addresses a topic that has come up numerous times in literature and class discussion which we attempt to investigate: the efficient utilisation of labelled data. High-quality labelled datasets is very expensive in terms of time, money and domain expertise, particularly in agricultural contexts where consistent quality standards must be maintained across diverse fruit varieties and environmental conditions. The dataset employed in this study contains images already organised by both quality level and fruit type through directory structure and filename conventions, yet limiting ourselves to quality classification alone would effectively discard half of the available label information.

The multi-task learning domain offers a mechanism to leverage this richer labelling scheme without collecting additional data, potentially improving the return on annotation investment. Recent discussions in the transfer learning literature suggest that related tasks may benefit from shared feature representations, as lower-level visual patterns such as edge detection, texture recognition and colour distribution often prove relevant across multiple classification objectives. Whether this hypothesis holds for fruit classification, where quality assessment might depend on fruit-specific characteristics, remains an empirical question we aim to address through comparative evaluation of single-task versus multi-task architectures.

The primary objective centres on developing convolutional neural network architectures capable of identifying the quality of fruit from visual data. This entails constructing models that can learn unique features directly from pixel level representations. CNNs offer particular advantages for this task through their hierarchical feature learning, where early layers may capture low-level patterns such as edges and textures, while deeper layers synthesise these into higher order abstractions that correspond to quality indicators.

But it is important to note that for this research project the objective extends beyond merely achieving acceptable classification accuracy. It involves understanding which architectural choices prove most consequential for this task and whether relatively simple networks suffice under different scenarios of input data or whether more complex designs yield proportional improvements performance.

The second objective investigates the comparative performance of single-task versus multi-task learning paradigms. Single-task models focus exclusively on quality classification, optimising their parameters to distinguish among good, mildly degraded and rotten produce. Multi-task architectures, by contrast, simultaneously predict both quality level and fruit type through a shared convolutional backbone that feeds into separate classification heads.

This dual-objective formulation raises questions about whether forcing the network to learn features useful for multiple related tasks improves generalisation or whether task interference diminishes performance on either objective. This objective speaks to broader discussions in transfer learning and multi-task optimisation about when parameter sharing proves advantageous and when task specific architectures remain preferable.

Accuracy offers an intuitive overview but may obscure class-specific performance disparities, particularly problematic when dealing with imbalanced datasets where certain quality categories appear more frequently than others. For this, various different performance metrics are introduced to analyse the output of the model and motivate the legitimacy of the findings.

Fourthly, analysing how variations in input data characteristics affect model performance represents a critical objective for understanding the practical constraints within this classification task. Colour information, for instance, might prove essential for distinguishing between early and advanced stages of degradation or texture patterns captured equally well in grayscale could suffice. Furthermore, we explore the role that image resolution plays in the trade-offs between computational efficiency and information preservation, higher resolutions retain finer details but demand greater processing resources and may increase training time substantially. Data augmentation techniques that artificially expand training sets through geometric transformations and photometric adjustments could improve robustness to variations in imaging conditions, or they might introduce artifacts that complicate learning.

The final objective synthesises findings across all experimental conditions to identify patterns that generalise beyond individual scenarios. This comparative analysis seeks to determine whether certain configurations consistently outperform alternatives regardless of specific implementation details or whether optimal approaches vary depending on contextual factors such as available computational resources, dataset characteristics, or operational requirements.

In summary, the research objectives comprise of:

\begin{enumerate}
    \item Develop CNN-based deep learning models for fruit classification and quality assessment
    \item Implement both single-task (quality only) and multi-task (fruit type and quality) learning approaches
    \item Evaluate model performance using multiple metrics: accuracy, precision, recall, F1-score, ROC curves, and AUC
    \item Analyse the impact of different input data characteristics on model performance
    \item Compare single-task versus multi-task learning performance to assess architectural trade-offs
\end{enumerate}

\section{Dataset and Model Implementation}

First we begin by acquiring and inspecting the dataset. The Fruit Quality Database (FruQ-DB) is used for this research study as the foundational data source. This dataset provides images of multiple fruit varieties across different quality states, organised hierarchically by fruit type and quality level.

Initial preprocessing involves structuring the data into training, validation and test partitions to support model development while maintaining strict separation between evaluation sets. The images have quality labels that are represented through directory organisation (Good, Mild, Rotten) and fruit type information are embedded in the filename prefixes. This labelling scheme enables both single-task quality classification and multi-task learning where fruit identification serves as an auxiliary objective.

For the data augmentation pipelines, we apply transformations such as random rotations, horizontal flips and adjustments to brightness and contrast, expanding the effective training set size while introducing controlled variability that may improve model robustness to more realistic unforeseen conditions not represented in the original dataset. These augmented images are saved separately, not affecting the original dataset.

For model development, we proceeded through implementation of convolutional neural network architectures in PyTorch. The architecture design follows established conventions for image classification networks, beginning with convolutional layers that extract spatial features through learned filter banks, followed by pooling operations that introduce translation invariance and reduce dimensionality. Thereafter, convolutional blocks increase filter depth while reducing spatial dimensions, a pattern that encourages hierarchical feature learning where early layers capture local patterns and deeper layers synthesise these into global representations. For single-task models, this convolutional backbone feeds into fully connected layers that produce quality class predictions. Multi-task architectures extend this design by branching after feature extraction into parallel classification heads, one for quality assessment, another for fruit type identification. This architectural choice embodies hypotheses about feature reusability across related visual tasks.

This experimental design split the research project into phases: Part A examines single-task quality classification under varying conditions, while Part B extends analysis to multi-task learning scenarios. This establishes clear baseline performance through single-task models before introducing the additional complexity of multi-task optimisation, allowing direct assessment of whether auxiliary objectives provide benefits or merely introduce confounding factors.

\section{The Two Research Parts and Different Scenarios}

Part A comprises three scenarios that manipulate input characteristics while maintaining focus on quality classification alone. Scenario 1 establishes baseline performance using standard RGB images pre-processed through resize operations and normalisation. This acts as an unaltered baseline for future comparisons that change the input scenarios. Scenario 2 converts images to grayscale, testing the hypothesis that colour information contributes critically to quality assessment, or conversely, that texture and structural features captured in intensity values is good enough for accurate classifications. This scenario addresses practical considerations about whether simpler single-channel representations might reduce computational requirements without sacrificing performance. Scenario 3 introduces data augmentation during training, applying random transformations that expand the effective dataset size while potentially improving generalisation to images captured under conditions not represented in the original training distribution. The dataset provides near perfect images, this is why Scenario 3 is so important to test the model to more realistic variation of image inputs.

Part B replicates each of these scenarios within a multi-task learning framework where models simultaneously predict fruit type and quality level. Scenario 1 establishes multi-task baseline performance with standard RGB inputs. Scenario 2 examines whether grayscale conversion affects both tasks equally or whether fruit type identification proves more colour dependent than quality assessment. Scenario 3 evaluates augmentation under multi-task learning, questioning whether synthetic variations benefit both objectives or introduce task specific biases that help one classification head while punishing or degrading the other.

\section{Training and Results}

A fixed random seed is used to control to ensure that results are repeatable and reproducible. Train/validation/test splits maintain strict separation, with test sets reserved exclusively for final evaluation after all architectural decisions and hyperparameter selections are complete. Each scenario generates comprehensive logs capturing training dynamics, validation metrics across epochs and final test set performance.

Results analysis synthesises findings across all scenarios through multiple analytical lenses. Quantitative comparison of performance metrics identifies which configurations achieve superior classification accuracy, precision, recall, and F1-scores, while ROC curves and AUC values reveal discriminative capacity across varying decision thresholds. Confusion matrices expose class-specific error patterns, indicating whether models systematically misclassify particular quality levels or fruit types, which represents insights that might suggest targeted refinements or reveal inherent ambiguities in the classification task itself. Then finally cross scenario comparisons assess the impact of individual factors: does grayscale conversion consistently degrade performance by some quantifiable margin, or do effects vary depending on whether models operate in single-task or multi-task mode? Do augmentation benefits depend on resolution, suggesting interactions between preprocessing choices?

Training curves track loss and accuracy evolution across epochs indicate whether models converge reliably or exhibit instability, whether they overfit to training data or maintain consistent performance across training and validation sets.
